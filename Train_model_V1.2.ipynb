# Model was trained using google colab

# Download Mask RCNN and install in root
%cd
!git clone --quiet https://github.com/matterport/Mask_RCNN.git
%cd ~/Mask_RCNN
!pip install -r requirements.txt
!python setup.py install

# Install and check tensorflow
!pip uninstall tensorflow
!pip install tensorflow-gpu==1.15.0
import tensorflow as tf
print('Tensorflow version:',tf.__version__)
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

# Install and check keras
!pip uninstall keras-nightly
!pip install keras==2.1.6
import keras
print('Keras version:',keras.__version__)

# Libraries
import os
import sys
import random
import math
import re
import time
import numpy as np
import cv2
import matplotlib
import matplotlib.pyplot as plt
import json
import pandas as pd
from PIL import Image, ImageDraw

from skimage.io import imread, imshow, imread_collection, concatenate_images
from skimage.transform import resize
from google.colab import drive

# connect to google drive
drive.mount('/content/drive')

# Relative path to .h5 weights file
WEIGHTS_FILE = None

# Relative path to annotations JSON file
TRAIN_ANNOTATIONS_FILE = "/content/drive/My Drive/HBO/Mask_RCNN/dataset/train/annotation_train_coco.json"

# Relative path to directory of images that pertain to annotations file
TRAIN_ANNOTATION_IMAGE_DIR = '/content/drive/My Drive/HBO/Mask_RCNN/dataset/train/images'

# Relative path to annotations JSON file
VALIDATION_ANNOTATIONS_FILE = "/content/drive/My Drive/HBO/Mask_RCNN/dataset/val/annotation_val_coco.json"

# Relative path to directory of images that pertain to annotations file
VALIDATION_ANNOTATION_IMAGE_DIR = '/content/drive/My Drive/HBO/Mask_RCNN/dataset/val/images'

# Number of epochs to train dataset on
NUM_EPOCHS = 20

# Name of model created
MODEL_NAME = "model_version_1.2"

from mrcnn.config import Config
import mrcnn.utils
import mrcnn.model as modellib
import mrcnn.visualize
from mrcnn.model import log

%matplotlib inline

# Root directory of the project
ROOT_DIR = os.getcwd()

# Directory to save logs and trained model
MODEL_DIR = os.path.join(ROOT_DIR, "logs")

class TrainConfig(Config):
  # Give the configuration a recognizable name
  NAME = MODEL_NAME
  
  # Train on 1 image per GPU. Batch size is 1
  GPU_COUNT = 1
  IMAGES_PER_GPU = 1
  
  # Number of classes (including background)
  NUM_CLASSES = 1 + 2

  # Min and max image dimensions
  IMAGE_MIN_DIM = 64
  IMAGE_MAX_DIM = 640

  # You can experiment with this number to see if it improves training
  STEPS_PER_EPOCH = 900
  
  # This is how often validation is run. If you are using too much hard drive space
  # on saved models (in the MODEL_DIR), try making this value larger.
  VALIDATION_STEPS = 250
  
  # Matterport originally used resnet101, but I downsized to fit it on my graphics card
  BACKBONE = 'resnet101'
  
  # To be honest, I haven't taken the time to figure out what these do
  PRN_ANCHOR_SCALES = (32, 64, 128, 256, 512)
  
  # Changed to 512 because that's how many the original MaskRCNN paper used
  TRAIN_ROIS_PER_IMAGE = 200
  MAX_GT_INSTANCES = 114
  POST_NMS_INFERENCE = 1000
  POST_NMS_TRAINING = 2000
  
  DETECTION_MAX_INSTANCES = 114
  DETECTION_MIN_CONFIDENCE = 0.1

config = TrainConfig()
config.display()

class CocoLikeDataset(mrcnn.utils.Dataset):
  def load_data(self, annotation_json, images_dir):
    # Load json from file
    json_file = open(annotation_json)
    coco_json = json.load(json_file)
    json_file.close()

    # Add the class names using the base method from utils.Dataset
    source_name = "coco_like"
    for category in coco_json['categories']:
      class_id = category['id']
      class_name = category['name']
      if class_id < 1:
        print('Error: Class id for "{}" cannot be less than one. (0 is reserved for the background)'.format(class_id))
        return
      
      self.add_class(source_name, class_id, class_name)
    
    # Get all annotations
    annotations = {}
    for annotation in coco_json['annotations']:
      image_id = annotation['image_id']
      if image_id not in annotations:
        annotations[image_id] = []
      annotations[image_id].append(annotation)
    
    # Get all images and add them to the dataset
    seen_images = {}
    for image in coco_json['images']:
      image_id = image['id']
      if image_id in seen_images:
        print("Warning: Skipping duplicate image id: {}".format(image))
      else:
        seen_images[image_id] = image
        try:
          image_file_name = image['file_name']
          image_width = image['width']
          image_height = image['height']
        except KeyError as key:
          print("Warning: Skipping image (id: {}) with missing key: {}".format(image_id, key))
        
        image_path = os.path.abspath(os.path.join(images_dir, image_file_name))
        image_annotations = annotations[image_id]

        # Add the image using the base method from utils.Dataset
        self.add_image(
            source=source_name,
            image_id=image_id,
            path=image_path,
            width=image_width,
            height=image_height,
            annotations=image_annotations
        )
  def load_mask(self, image_id):
    image_info = self.image_info[image_id]
    annotations = image_info['annotations']
    instance_masks = []
    class_ids = []

    for annotation in annotations:
      class_id = annotation['category_id']
      mask = Image.new('1', (image_info['width'], image_info['height']))
      mask_draw = ImageDraw.ImageDraw(mask, '1')
      for segmentation in annotation['segmentation']:
        mask_draw.polygon(segmentation, fill=1)
        bool_array = np.array(mask) > 0
        instance_masks.append(bool_array)
        class_ids.append(class_id)
    
    mask = np.dstack(instance_masks)
    class_ids = np.array(class_ids, dtype=np.int32)

    return mask, class_ids

# Training dataset
dataset_train = CocoLikeDataset()
dataset_train.load_data(TRAIN_ANNOTATIONS_FILE, TRAIN_ANNOTATION_IMAGE_DIR)
dataset_train.prepare()

# Validation dataset
dataset_val = CocoLikeDataset()
dataset_val.load_data(VALIDATION_ANNOTATIONS_FILE, VALIDATION_ANNOTATION_IMAGE_DIR)
dataset_val.prepare()

# Create model in training mode
model = modellib.MaskRCNN(mode = "training", config = config, model_dir = MODEL_DIR)

# Train model
model.train(dataset_train, dataset_val, learning_rate = config.LEARNING_RATE, epochs = NUM_EPOCHS, layers = 'all')
